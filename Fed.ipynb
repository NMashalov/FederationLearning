{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOED99ra9cw8OT5n9EIFZyq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NMashalov/FederationLearning/blob/master/Fed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reserach on zero-gradient in federation learning\n",
        "\n",
        "Code was highly inspired by implementation in paper:\n",
        "\n",
        "https://arxiv.org/pdf/2304.07861.pdf\n"
      ],
      "metadata": {
        "id": "DIPpmp5EANwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we'll work without samples\n",
        "$$\n",
        "    f(x,\\xi) ={\\left(<x,\\xi> - \\sum_{i=1}^d\\xi_i\\right) ^2}+ \\|x\\|_\\infty + \\delta\n",
        "$$\n",
        "\n",
        "$x \\in R^d$\n",
        "\n",
        "$\\xi_i \\sim U[0,1]$\n",
        "\n",
        "$\\delta \\sim \\mathbf{N(0,\\sigma^2)}$\n",
        "\n",
        "Optimization set:\n",
        "\n",
        "$$\n",
        "    D = \\{|x|=1, x > 0\\}\n",
        "$$\n",
        "\n",
        "\n",
        "Recall, infinity norm is max among all coordinates\n",
        "\n",
        "$$\n",
        "    \\|x\\|_\\infty = \\max\\limits_{i=1,n} x_i\n",
        "$$"
      ],
      "metadata": {
        "id": "CCUskBQZYfFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithm implmentation"
      ],
      "metadata": {
        "id": "yuhvBZFsSWrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "2XTVjPoKA2QC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### HYPERPARAMS\n",
        "# vector dim\n",
        "D = 20\n",
        "# number of machines\n",
        "M = 32\n",
        "# smoothing gamma\n",
        "G = 0.001\n",
        "# number of samples\n",
        "N = 1000"
      ],
      "metadata": {
        "id": "H-BiTnYqZgQt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# N x D matrix\n",
        "X_train = np.random.uniform(size=(N,D))"
      ],
      "metadata": {
        "id": "4DY3_JIPBoFC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(x,xi, noise = 0):\n",
        "    \"\"\"\n",
        "    Compute optimization function\n",
        "\n",
        "    Argument:\n",
        "        x: tensor [Machines number, Vector Dim]\n",
        "        xi: tensor sample from []\n",
        "        noise:\n",
        "    \"\"\"\n",
        "    return (x @ xi - np.sum(xi,axis=1))  + np.max(x,dim=1) + noise * np.random.randn(D)"
      ],
      "metadata": {
        "id": "xODWI-JkSuNz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient approximation\n",
        "\n",
        "Two points l1:\n",
        "$$\n",
        "\\nabla f_\\gamma (x, ξ, e) = \\frac{d}{2γ}\n",
        "\\left(f_{δ1}\n",
        "(x + γe, ξ) − f_{δ2}\n",
        "(x − γe, ξ)\\right) sign(e)\n",
        "$$\n",
        "\n",
        "\n",
        "Two points l2:\n",
        "$$\n",
        "\\nabla f_\\gamma (x, ξ, e) = \\frac{d}{2γ}\n",
        "\\left(f_{δ1}\n",
        "(x + γe, ξ) − f_{δ2}\n",
        "(x − γe, ξ)\\right) e\n",
        "$$"
      ],
      "metadata": {
        "id": "BfZjIKa4XYeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_spherical(npoints, ndim=D):\n",
        "    vec = np.random.randn(ndim, npoints)\n",
        "    vec /= np.linalg.norm(vec, axis=0)\n",
        "    return vec"
      ],
      "metadata": {
        "id": "tKnBMxCTZ5US"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import typing as tp\n",
        "\n",
        "method_type = tp.Literal['l1','l2']\n",
        "\n",
        "def calc_grad(x: np.array,xi: np.array, method_type: method_type = 'l2'):\n",
        "    if method_type == 'l2':\n",
        "        e = sample_spherical(M)\n",
        "        grad = D / (2* G) * (loss(x + G * e,xi) - loss(x - G * e,xi)) * e\n",
        "    elif method_type == 'l1':\n",
        "        raise NotImplementedError('l1')\n",
        "        grad = D / (2* G) * (loss(x + G * e,xi) - loss(x - G * e,xi)) * e\n",
        "    else:\n",
        "        raise NotImplementedError('No methods')"
      ],
      "metadata": {
        "id": "YlAUXpteaua8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Minibatch SGD"
      ],
      "metadata": {
        "id": "1j2CFtfABW6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_grad(x,batch_size):\n",
        "    samples_idx = np.random.choice(N, batch_size, replace=True)\n",
        "    X_sampled = X_train[samples_idx, :]\n",
        "    return calc_grad(x,X_sampled)"
      ],
      "metadata": {
        "id": "m4PfXn1MBhJs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def population_loss(x):\n",
        "        \"\"\"\n",
        "        Compute the population loss for all training samples.\n",
        "\n",
        "        Argument:\n",
        "            weight: w\n",
        "        \"\"\"\n",
        "        return loss(x, X_train)"
      ],
      "metadata": {
        "id": "7Ht_oTewHDX0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "T = 1000 # number of oracle calls\n",
        "K = 10 # communication rounds\n",
        "\n",
        "eta = 1e-3\n",
        "beta = 2\n",
        "alpha = 2\n",
        "gamma = 0.1\n",
        "\n",
        "local_batch = 10\n",
        "\n",
        "w = np.random.randn(D)\n",
        "w_ag = np.copy(w)\n",
        "\n",
        "seq = pd.Series(name='loss')\n",
        "for iter_cnt in range(0, T+1, K):\n",
        "    w_md = (1/beta) * w + (1-(1/beta))*w_ag\n",
        "    grad_md = sample_grad(w_md, M*K*local_batch)\n",
        "    w_ag = w_md - eta * grad_md\n",
        "    w = (1 - (1/alpha)) * w + (1/alpha) * \\\n",
        "        w_md - gamma * grad_md"
      ],
      "metadata": {
        "id": "7KAW5e_nBKZ3",
        "outputId": "4c47499f-586f-4209-8d94-5e229e1f1104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-717f842010be>:15: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  seq = pd.Series(name='loss')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-717f842010be>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miter_cnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mw_md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw_ag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mgrad_md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlocal_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mw_ag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_md\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad_md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-01a28fe79795>\u001b[0m in \u001b[0;36msample_grad\u001b[0;34m(x, batch_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msamples_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mX_sampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msamples_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcalc_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_sampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-a40a10d83044>\u001b[0m in \u001b[0;36mcalc_grad\u001b[0;34m(x, xi, method_type)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_spherical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (20,) (20,32) "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FED_AVG"
      ],
      "metadata": {
        "id": "sGZiThoSWFR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def broadcast_avg(pool):\n",
        "    \"\"\"\n",
        "    Helper functions for FedAc and FedAvg, average and broadcast the weights.\n",
        "    \"\"\"\n",
        "    avg = pool.mean(axis=0)\n",
        "    pool = np.repeat(avg[np.newaxis, :], pool.shape[0], axis=0)\n",
        "    return pool"
      ],
      "metadata": {
        "id": "Mf9C_jHxZ88g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def fedavg(eta, M, K, T,  record_intvl=512, print_intvl=8192, SEED=0):\n",
        "        \"\"\"\n",
        "        Simulate Federated Averaging (FedAvg, a.k.a. Local-SGD, or Parallel SGD, etc.)\n",
        "\n",
        "        Arguments:\n",
        "            eta:    learning rate\n",
        "            M:      number of workers\n",
        "            K:      synchronization interval, (i.e., local steps)\n",
        "            T:      total parallel runtime\n",
        "            record_intvl:   compute the population loss every record_intvl steps.\n",
        "\n",
        "        Return:\n",
        "            A pandas.Series object of population loss evaluated.\n",
        "        \"\"\"\n",
        "        # set of\n",
        "        np.random.seed(SEED)\n",
        "        # weights on nodes\n",
        "        common_init_w = np.random.randn(D)\n",
        "        #\n",
        "        w_pool = np.repeat(common_init_w[np.newaxis, :], M, axis=0)\n",
        "\n",
        "        seq = pd.Series(name='loss')\n",
        "        for iter_cnt in range(T+1):\n",
        "            if iter_cnt % K == 0:\n",
        "                w_pool = broadcast_avg(w_pool)\n",
        "\n",
        "                if iter_cnt % record_intvl == 0:\n",
        "                    seq.at[iter_cnt] = loss(w_pool[0, :])\n",
        "\n",
        "            w_pool -= eta * calc_grad\n",
        "        return seq"
      ],
      "metadata": {
        "id": "OCDctHaKRc8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "UOWNhhSASkYA",
        "outputId": "8d49fd97-84b8-420b-d455-499e325607cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-7371d8ac25c1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalc_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: calc_grad() missing 1 required positional argument: 'x'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Smooth function"
      ],
      "metadata": {
        "id": "IobyHb8uiMBP"
      }
    }
  ]
}