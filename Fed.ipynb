{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoNI3pnOc5XkotwVSVD4x0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NMashalov/FederationLearning/blob/master/Fed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reserach on zero-gradient in federation learning\n",
        "\n",
        "Code was highly inspired by implementation in paper:\n",
        "\n",
        "https://arxiv.org/pdf/2304.07861.pdf\n"
      ],
      "metadata": {
        "id": "DIPpmp5EANwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we'll work without samples\n",
        "$$\n",
        "    f(x,\\xi), = b_\\xi + |x|_\\infty\n",
        "$$\n",
        "\n",
        "$\\xi$ are samples from $\\mathbf{N}(0,I)$.\n",
        "\n",
        "$x$ is restricted to simplex:\n",
        "\n",
        "$$\n",
        "    D = \\{|x|=1, x > 0\\}\n",
        "$$\n",
        "\n",
        "\n",
        "Recall, infinity norm is max among all coordinates\n",
        "\n",
        "$$\n",
        "    \\|x\\|_\\infty = \\max\\limits_{i=1,n} x_i\n",
        "$$"
      ],
      "metadata": {
        "id": "CCUskBQZYfFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithm implmentation"
      ],
      "metadata": {
        "id": "yuhvBZFsSWrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### HYPERPARAMS\n",
        "\n",
        "# vector dim\n",
        "D = 20\n",
        "# number of machines\n",
        "M = 32\n",
        "# smoothing gamma\n",
        "G = 0.001"
      ],
      "metadata": {
        "id": "H-BiTnYqZgQt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# fix random vector b\n",
        "\n",
        "b = np.random.randn(D)\n",
        "\n",
        "b = b / np.linalg.norm(b)\n",
        "b.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WXg-xWaZSj1",
        "outputId": "597f2d0e-c4b2-4670-f80f-7ebff2a42c15"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20,)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(x, noise = 0):\n",
        "    \"\"\"\n",
        "    Compute optimization function\n",
        "\n",
        "    Argument:\n",
        "        x: tensor [Machines number, Vector Dim\n",
        "        noise:\n",
        "    \"\"\"\n",
        "    return x @ b + np.max(x,dim=1) + noise * np.random.randn(D)"
      ],
      "metadata": {
        "id": "xODWI-JkSuNz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient approximation\n",
        "\n",
        "Two points l1:\n",
        "$$\n",
        "\\nabla f_\\gamma (x, ξ, e) = \\frac{d}{2γ}\n",
        "\\left(f_{δ1}\n",
        "(x + γe, ξ) − f_{δ2}\n",
        "(x − γe, ξ)\\right) sign(e)\n",
        "$$\n",
        "\n",
        "\n",
        "Two points l2:\n",
        "$$\n",
        "\\nabla f_\\gamma (x, ξ, e) = \\frac{d}{2γ}\n",
        "\\left(f_{δ1}\n",
        "(x + γe, ξ) − f_{δ2}\n",
        "(x − γe, ξ)\\right) e\n",
        "$$"
      ],
      "metadata": {
        "id": "BfZjIKa4XYeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_spherical(npoints, ndim=D):\n",
        "    vec = np.random.randn(ndim, npoints)\n",
        "    vec /= np.linalg.norm(vec, axis=0)\n",
        "    return vec"
      ],
      "metadata": {
        "id": "tKnBMxCTZ5US"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import typing as tp\n",
        "\n",
        "method_type = tp.Literal['l1','l2']\n",
        "\n",
        "def calc_grad(x: np.array, method_type: method_type = 'l2'):\n",
        "    if method_type == 'l2':\n",
        "        e = sample_spherical(M)\n",
        "        grad = D / (2* G) * (loss(x + G * e ) - loss(x - G * e )) * e\n",
        "    elif method_type == 'l1':\n",
        "        raise NotImplementedError('l1')\n",
        "        grad = D / (2* G) * (loss(x + G * e ) - loss(x - G * e )) * e\n",
        "    else:\n",
        "        raise NotImplementedError('No methods')"
      ],
      "metadata": {
        "id": "YlAUXpteaua8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FED_AVG"
      ],
      "metadata": {
        "id": "sGZiThoSWFR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def broadcast_avg(pool):\n",
        "    \"\"\"\n",
        "    Helper functions for FedAc and FedAvg, average and broadcast the weights.\n",
        "    \"\"\"\n",
        "    avg = pool.mean(axis=0)\n",
        "    pool = np.repeat(avg[np.newaxis, :], pool.shape[0], axis=0)\n",
        "    return pool"
      ],
      "metadata": {
        "id": "Mf9C_jHxZ88g"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def fedavg(eta, M, K, T,  record_intvl=512, print_intvl=8192, SEED=0):\n",
        "        \"\"\"\n",
        "        Simulate Federated Averaging (FedAvg, a.k.a. Local-SGD, or Parallel SGD, etc.)\n",
        "\n",
        "        Arguments:\n",
        "            eta:    learning rate\n",
        "            M:      number of workers\n",
        "            K:      synchronization interval, (i.e., local steps)\n",
        "            T:      total parallel runtime\n",
        "            record_intvl:   compute the population loss every record_intvl steps.\n",
        "\n",
        "        Return:\n",
        "            A pandas.Series object of population loss evaluated.\n",
        "        \"\"\"\n",
        "        # set of\n",
        "        np.random.seed(SEED)\n",
        "        # weights on nodes\n",
        "        common_init_w = np.random.randn(D)\n",
        "        #\n",
        "        w_pool = np.repeat(common_init_w[np.newaxis, :], M, axis=0)\n",
        "\n",
        "        seq = pd.Series(name='loss')\n",
        "        for iter_cnt in range(T+1):\n",
        "            if iter_cnt % K == 0:\n",
        "                w_pool = broadcast_avg(w_pool)\n",
        "\n",
        "                if iter_cnt % record_intvl == 0:\n",
        "                    seq.at[iter_cnt] = loss(w_pool[0, :])\n",
        "\n",
        "            w_pool -= eta * calc_grad\n",
        "        return seq"
      ],
      "metadata": {
        "id": "OCDctHaKRc8K"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "UOWNhhSASkYA",
        "outputId": "8d49fd97-84b8-420b-d455-499e325607cf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-7371d8ac25c1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalc_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: calc_grad() missing 1 required positional argument: 'x'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Smooth function"
      ],
      "metadata": {
        "id": "IobyHb8uiMBP"
      }
    }
  ]
}